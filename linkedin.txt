pip install layker today — Lakehouse-Aligned YAML Kit for Engineering Rules

Excited to share my first published Python package: Layker — a Spark-native, lake-layer, infrastructure-as-code toolkit. It treats table metadata (schema, tags, comments, masking rules, row filters, constraints, properties, owner) as plain-English YAML you can review in PRs and run safely in jobs.

Why Layker (vs. classic migration tools like Liquibase/Flyway)?
Those are great for SQL migrations, but they typically don’t model all the table metadata for Spark/Delta in a declarative, auditable way. With Layker, you don’t hand-code “set this tag here, row filter there” across scattered notebooks — the YAML is the source of truth, and the engine enforces it with built-in validation so you know config is sane before it runs.

AI-friendly: Specs are readable YAML, all in one place. No more asking a model to run multiple queries and stitch results — Layker is your lake layer with the info centralized.

How it works
	•	Validate → Diff → Apply → Audit
	•	Applies only what changed; if nothing changed it exits cleanly (no noise)
	•	Safe schema evolution (add/rename/drop) gated by required Delta properties
	•	Structured audit per change: before JSON, differences, after JSON